#!/usr/bin/env python3
"""
Cloud Function para coletar indicadores econ√¥micos do Banco Central
e carregar no BigQuery
"""
import os
import pandas as pd
import requests
import json
import base64
from datetime import datetime
from google.cloud import bigquery
import functions_framework


# =============================================================================
# CONFIGURA√á√ïES
# =============================================================================
PROJECT_ID = os.environ.get("PROJECT_ID", "trabalho-final-pdm-478021")
DATASET_ID = os.environ.get("DATASET_ID", "main_database")
TABLE_NAME = os.environ.get("TABLE_NAME", "banco_central_indicadores")

# --- C√≥digos das S√©ries do SGS do BCB (Mensais) ---
# Voc√™ pode buscar outros c√≥digos na p√°gina do BCB/SGS
SERIES_BCB = {
    # === INDICADORES DE CUSTO ===
    4390: 'selic_meta_mensal',  # Taxa SELIC (custo de capital)

    # === INFLA√á√ÉO (afeta custos e margens) ===
    433: 'ipca_acumulado_12m',  # IPCA acumulado 12 meses
    13522: 'ipca_mensal',  # IPCA mensal (varia√ß√£o mais imediata)

    # === CR√âDITO E INADIMPL√äNCIA ===
    21082: 'inadimplencia_pj_livre',  # Inadimpl√™ncia PJ - Recursos Livres
    20542: 'volume_credito_pj_total',  # Volume de cr√©dito PJ total (R$ milh√µes)
    20714: 'spread_credito_pj',  # Spread m√©dio das opera√ß√µes de cr√©dito PJ

    # === C√ÇMBIO ===
    10813: 'cambio_dolar_media_mensal',  # D√≥lar - M√©dia mensal de venda

    # === ATIVIDADE ECON√îMICA ===
    24363: 'ibc_br_dessazonalizado',  # IBC-Br (proxy do PIB mensal)

    # === CONFIAN√áA E EXPECTATIVAS ===
    4394: 'icei',  # √çndice de Confian√ßa Empresarial (FGV)
    7341: 'nivel_utilizacao_capacidade',  # N√≠vel de Utiliza√ß√£o da Capacidade Instalada - Ind√∫stria

    # === MERCADO DE TRABALHO ===
    24369: 'taxa_desemprego',  # Taxa de desemprego (PNAD Cont√≠nua)
}

DATA_INICIO_COLETA = os.environ.get("DATA_INICIO", "01/01/2016")


# =============================================================================
# FUN√á√ïES
# =============================================================================

def buscar_serie_temporal_bcb(codigo_serie, nome_coluna, data_inicio="01/01/2010"):
    """
    Busca uma s√©rie temporal no Banco Central do Brasil (BCB) via API do SGS.

    Args:
        codigo_serie (int): C√≥digo da s√©rie no SGS do BCB.
        nome_coluna (str): Nome a ser dado √† coluna de dados no DataFrame.
        data_inicio (str): Data de in√≠cio da busca no formato 'dd/mm/aaaa'.

    Returns:
        pd.DataFrame: DataFrame com as colunas 'ano_mes' e a s√©rie de dados.
    """
    # URL da API do SGS do BCB
    url = f"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{codigo_serie}/dados?formato=json&dataInicial={data_inicio}"
    
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        dados = response.json()
        
    except requests.exceptions.RequestException as e:
        print(f"Erro ao buscar a s√©rie {nome_coluna} (C√≥digo {codigo_serie}): {e}")
        return pd.DataFrame()

    if not dados:
        print(f"A s√©rie {nome_coluna} (C√≥digo {codigo_serie}) retornou dados vazios.")
        return pd.DataFrame()

    # Cria o DataFrame a partir do JSON
    df = pd.DataFrame(dados)
    
    # Renomeia as colunas
    df.rename(columns={'valor': nome_coluna, 'data': 'data_completa'}, inplace=True)
    
    # Converte 'data' para o formato datetime
    df['data_completa'] = pd.to_datetime(df['data_completa'], format='%d/%m/%Y')
    
    # Cria a coluna 'ano_mes' no formato YYYY-MM
    df['ano_mes'] = df['data_completa'].dt.strftime('%Y-%m')
    
    # Converte valores para num√©rico
    df[nome_coluna] = pd.to_numeric(df[nome_coluna], errors='coerce')

    # ‚úÖ SOLU√á√ÉO: Agrupa por ano_mes e pega a M√âDIA (ou √∫ltimo valor)
    # Para s√©ries di√°rias, isso calcula a m√©dia mensal
    # Para s√©ries j√° mensais, mant√©m o valor √∫nico
    df_mensal = df.groupby('ano_mes', as_index=False).agg({
        nome_coluna: 'mean'  # Usa 'mean' para m√©dia ou 'last' para √∫ltimo valor do m√™s
    })

    return df_mensal


def coletar_indicadores_economicos():
    """
    Coleta todos os indicadores econ√¥micos do BCB
    
    Returns:
        pd.DataFrame: DataFrame consolidado com todos os indicadores
    """
    DATA_INICIO_COLETA = os.environ.get("DATA_INICIO", "01/01/2016")

    dfs_indicadores = []

    for codigo, nome in SERIES_BCB.items():
        print(f"Coletando s√©rie: {nome} (C√≥digo: {codigo})...")
        df_serie = buscar_serie_temporal_bcb(codigo, nome, DATA_INICIO_COLETA)
        if not df_serie.empty:
            dfs_indicadores.append(df_serie)

    if not dfs_indicadores:
        print("Nenhuma s√©rie foi coletada com sucesso.")
        return pd.DataFrame()

    # 1. Combina todos os DataFrames em um √∫nico
    df_final = dfs_indicadores[0]
    for i in range(1, len(dfs_indicadores)):
        df_final = pd.merge(df_final, dfs_indicadores[i], on='ano_mes', how='outer')

    # 2. Converte todas as colunas de valor para tipo num√©rico
    for col in df_final.columns:
        if col != 'ano_mes':
            df_final[col] = pd.to_numeric(df_final[col], errors='coerce')

    # 3. Ordena o DataFrame por ano_mes
    df_final.sort_values(by='ano_mes', inplace=True)
    df_final.reset_index(drop=True, inplace=True)

    # ‚úÖ VERIFICA√á√ÉO ADICIONAL: Remove duplicatas caso ainda existam
    df_final = df_final.drop_duplicates(subset=['ano_mes'], keep='first')

    print("\nColeta de Indicadores Econ√¥micos Finalizada.")
    print(f"DataFrame Final (Shape: {df_final.shape}):")
    print(f"Per√≠odo: {df_final['ano_mes'].min()} a {df_final['ano_mes'].max()}")
    print(f"Total de meses √∫nicos: {df_final['ano_mes'].nunique()}")

    return df_final


def criar_schema_bigquery():
    """Cria schema da tabela no BigQuery"""
    schema = [
        bigquery.SchemaField("ano_mes", "STRING", mode="REQUIRED"),
    ]
    
    # Adicionar colunas para cada indicador
    for nome in SERIES_BCB.values():
        schema.append(
            bigquery.SchemaField(nome, "FLOAT64", mode="NULLABLE")
        )
    
    return schema


def carregar_no_bigquery(df, table_name=None, write_mode="WRITE_APPEND"):
    """
    Carrega DataFrame no BigQuery
    
    Args:
        df: DataFrame pandas com os dados
        table_name: Nome da tabela (opcional, usa TABLE_NAME se None)
        write_mode: Modo de escrita (WRITE_APPEND ou WRITE_TRUNCATE)
        
    Returns:
        Dict com status e estat√≠sticas
    """
    if df.empty:
        print("‚ö†Ô∏è  DataFrame vazio, nada para carregar")
        return {'status': 'skipped', 'rows': 0}
    
    # Se n√£o foi especificado um nome de tabela, usa o padr√£o
    table_name = table_name or TABLE_NAME
    
    client = bigquery.Client(project=PROJECT_ID)
    table_ref = f"{PROJECT_ID}.{DATASET_ID}.{table_name}"
    
    # Configurar job
    job_config = bigquery.LoadJobConfig(
        schema=criar_schema_bigquery(),
        write_disposition=write_mode,
        source_format=bigquery.SourceFormat.PARQUET,  # Mais eficiente que CSV
    )
    
    print(f"\nüìä Carregando {len(df)} linhas no BigQuery...")
    print(f"   Tabela: {table_ref}")
    print(f"   Modo: {write_mode}")
    
    # Converter DataFrame para Parquet em mem√≥ria
    from io import BytesIO
    import pyarrow as pa
    import pyarrow.parquet as pq
    
    buffer = BytesIO()
    table = pa.Table.from_pandas(df)
    pq.write_table(table, buffer)
    buffer.seek(0)
    
    # Upload para BigQuery
    load_job = client.load_table_from_file(
        buffer,
        table_ref,
        job_config=job_config
    )
    
    try:
        load_job.result()
        rows = load_job.output_rows or len(df)
        print(f"‚úÖ Sucesso! {rows:,} linhas carregadas")
        
        return {
            'status': 'success',
            'rows': rows,
            'job_id': load_job.job_id,
            'table': table_name
        }
    except Exception as e:
        print(f"‚ùå Erro ao carregar no BigQuery: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'rows': 0,
            'table': table_name
        }


# =============================================================================
# CLOUD FUNCTION HANDLERS
# =============================================================================

@functions_framework.http
def banco_central_http(request):
    """Handler HTTP - processa indicadores econ√¥micos"""
    print('=' * 80)
    print('COLETAR INDICADORES ECON√îMICOS - BANCO CENTRAL')
    print('=' * 80)
    
    # Coletar indicadores
    df = coletar_indicadores_economicos()
    
    if df.empty:
        return {'error': 'Nenhum dado coletado'}, 400
    
    print(f"\nüìä Dados coletados: {len(df)} linhas")
    print(f"   Per√≠odo: {df['ano_mes'].min()} at√© {df['ano_mes'].max()}")
    
    # Determinar modo de escrita
    write_mode = request.args.get('mode', 'WRITE_APPEND')
    
    # Carregar vers√£o bronze (dados brutos)
    bronze_result = carregar_no_bigquery(df, f"{TABLE_NAME}_bronze", write_mode)
    
    # Criar vers√£o silver (dados tratados - preenchimento de nulos)
    df_silver = df.fillna(df.mean(numeric_only=True))
    silver_result = carregar_no_bigquery(df_silver, f"{TABLE_NAME}_silver", write_mode)
    
    return {
        'status': 'success' if bronze_result['status'] == 'success' and silver_result['status'] == 'success' else 'partial',
        'bronze': {
            'status': bronze_result['status'],
            'rows': bronze_result['rows']
        },
        'silver': {
            'status': silver_result['status'],
            'rows': silver_result['rows']
        },
        'data_shape': df.shape,
        'period': {
            'start': df['ano_mes'].min(),
            'end': df['ano_mes'].max()
        }
    }, 200


@functions_framework.cloud_event
def banco_central_pubsub(cloud_event):
    """Handler Pub/Sub - processa indicadores econ√¥micos (para agendamento)"""
    try:
        message_data_str = base64.b64decode(
            cloud_event.data["message"]["data"]
        ).decode("utf-8")
        message_data = json.loads(message_data_str) if message_data_str else {}
    except Exception:
        message_data = {}
    
    print('=' * 80)
    print('COLETAR INDICADORES ECON√îMICOS - BANCO CENTRAL (Pub/Sub)')
    print('=' * 80)
    
    # Coletar indicadores
    df = coletar_indicadores_economicos()
    
    if df.empty:
        return {'status': 'error', 'error': 'Nenhum dado coletado'}
    
    print(f"\nüìä Dados coletados: {len(df)} linhas")
    print(f"   Per√≠odo: {df['ano_mes'].min()} at√© {df['ano_mes'].max()}")
    
    # Modo de escrita da mensagem
    write_mode = message_data.get('mode', 'WRITE_APPEND')
    
    # Carregar vers√£o bronze (dados brutos)
    bronze_result = carregar_no_bigquery(df, f"{TABLE_NAME}_bronze", write_mode)
    
    # Criar vers√£o silver (dados tratados - preenchimento de nulos)
    df_silver = df.fillna(df.mean(numeric_only=True))
    silver_result = carregar_no_bigquery(df_silver, f"{TABLE_NAME}_silver", write_mode)
    
    return {
        'status': 'success' if bronze_result['status'] == 'success' and silver_result['status'] == 'success' else 'partial',
        'bronze': bronze_result,
        'silver': silver_result,
        'rows': len(df),
        'period': {
            'start': df['ano_mes'].min(),
            'end': df['ano_mes'].max()
        }
    }


if __name__ == '__main__':
    # Teste local
    from flask import Request
    request = Request.from_values()
    banco_central_http(request)